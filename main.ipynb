{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af8adcb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nilskluewer/GitHub/Emotion-Classification-Langgraph/.venv/lib/python3.13/site-packages/google_crc32c/__init__.py:29: RuntimeWarning: As the c extension couldn't be imported, `google-crc32c` is using a pure python implementation that is significantly slower. If possible, please configure a c build environment and compile the extension\n",
      "  warnings.warn(_SLOW_CRC32C_WARNING, RuntimeWarning)\n",
      "/Users/nilskluewer/GitHub/Emotion-Classification-Langgraph/.venv/lib/python3.13/site-packages/langsmith/client.py:261: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHECK 1\n",
      "CHECK 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| response: candidates {\n",
      "                content {\n",
      "                  role: \"model\"\n",
      "                  parts {\n",
      "                    text: \"{\\\"core_affect_analysis\\\": {\\\"thought_process\\\": \\\"Given the \\\\\\\"context_sphere\\\\\\\" contains only \\\\\\\"Test\\\\\\\", there is no user comment data to analyze core affect.  A proper analysis would involve examining the valence (pleasantness/unpleasantness) and arousal (activation/deactivation) expressed in the user\\'s comments.  With real data, I would look for language expressing or implying affective states, considering physiological descriptions (e.g., \\\\\\\"heart racing\\\\\\\"), emotion words (e.g., \\\\\\\"angry\\\\\\\"), and expressive language (e.g., \\\\\\\"That\\'s ridiculous!\\\\\\\").  Neuroscientifically, high arousal might be reflected in exclamatory punctuation or capitalized words, suggesting heightened activity in the autonomic nervous system.\\\", \\\"valence\\\": \\\"Neutral.  No comments are available for analysis.\\\", \\\"arousal\\\": \\\"Neutral. No comments are available for analysis.\\\", \\\"patterns_observed\\\": \\\"No patterns observable.\\\", "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidates {\n",
      "  content {\n",
      "    role: \"model\"\n",
      "    parts {\n",
      "      text: \"{\\\"core_affect_analysis\\\": {\\\"thought_process\\\": \\\"Given the \\\\\\\"context_sphere\\\\\\\" contains only \\\\\\\"Test\\\\\\\", there is no user comment data to analyze core affect.  A proper analysis would involve examining the valence (pleasantness/unpleasantness) and arousal (activation/deactivation) expressed in the user\\'s comments.  With real data, I would look for language expressing or implying affective states, considering physiological descriptions (e.g., \\\\\\\"heart racing\\\\\\\"), emotion words (e.g., \\\\\\\"angry\\\\\\\"), and expressive language (e.g., \\\\\\\"That\\'s ridiculous!\\\\\\\").  Neuroscientifically, high arousal might be reflected in exclamatory punctuation or capitalized words, suggesting heightened activity in the autonomic nervous system.\\\", \\\"valence\\\": \\\"Neutral.  No comments are available for analysis.\\\", \\\"arousal\\\": \\\"Neutral. No comments are available for analysis.\\\", \\\"patterns_observed\\\": \\\"No patterns observable.\\\", \\\"anomalous_observations\\\": \\\"No anomalous observations.\\\", \\\"rationale\\\": \\\"The absence of user comments prevents any meaningful analysis of core affect.  With actual data, I would triangulate linguistic cues, contextual factors, and potential physiological indicators implied in the text to infer core affective states, acknowledging the inherent limitations in interpreting online text.\\\"}, \\\"cognitive_appraisal_and_conceptualization\\\": {\\\"thought_process\\\": \\\"With no user comments in the provided \\\\\\\"context_sphere\\\\\\\", analyzing cognitive appraisals is impossible.  A robust analysis would involve examining how the user interprets and evaluates the situation based on their comments. I would look for evidence of their goals, values, and beliefs influencing their emotional responses.  For example, if a user perceives a comment as a personal attack, they might experience anger.  Cognitive science principles would inform my interpretation of their language use and reasoning.\\\", \\\"analysis\\\": \\\"No analysis possible due to lack of data.\\\", \\\"patterns_observed\\\": \\\"No patterns observable.\\\", \\\"anomalous_observations\\\": \\\"No anomalous observations.\\\", \\\"rationale\\\": \\\"The absence of user comments precludes any analysis of cognitive appraisals.  With real data, I would examine the user\\'s language for appraisals of relevance, implications, coping potential, and normative significance, drawing on psychological theories of appraisal to understand how these shape emotional responses.\\\"}, \\\"cultural_and_social_context\\\": {\\\"thought_process\\\": \\\"Analyzing cultural and social context is impossible without actual user comments.  A thorough analysis would consider the norms and values of the Der Standard forum and broader societal influences.  For example, political polarization might influence how users react to certain topics.  I would also consider the specific thread\\'s context and the user\\'s apparent social dynamics within the forum.\\\", \\\"analysis\\\": \\\"No analysis possible due to lack of data.\\\", \\\"patterns_observed\\\": \\\"No patterns observable.\\\", \\\"anomalous_observations\\\": \\\"No anomalous observations.\\\", \\\"rationale\\\": \\\"The lack of user comments prevents any analysis of cultural and social context.  With real data, I would draw on sociological and anthropological theories to understand how cultural norms, social dynamics, and historical context shape emotional expression and interpretation within the specific online community.\\\"}, \\\"emotion_construction_analysis\\\": {\\\"thought_process\\\": \\\"Since the \\\\\\\"context_sphere\\\\\\\" lacks user comments, analyzing emotion construction is not feasible.  A comprehensive analysis would integrate core affect, cognitive appraisals, conceptualizations, and contextual factors to understand how the user constructs their emotional experience.  I would look for how these elements interact to produce specific emotional instances, recognizing that emotions are not simply read out but built in the moment.\\\", \\\"analysis\\\": \\\"No analysis possible due to lack of data.\\\", \\\"patterns_observed\\\": \\\"No patterns observable.\\\", \\\"anomalous_observations\\\": \\\"No anomalous observations.\\\", \\\"rationale\\\": \\\"The absence of user comments prevents any analysis of emotion construction.  With real data, I would synthesize insights from the previous analyses to understand how core affect, cognitive appraisals, conceptualizations, and contextual factors dynamically interact to create the user\\'s emotional experiences, highlighting the constructed nature of emotions as emphasized in my theory.\\\"}, \\\"emotional_dynamics_and_changes\\\": {\\\"thought_process\\\": \\\"Without user comments, analyzing emotional dynamics is impossible.  A proper analysis would involve tracking changes in the user\\'s emotional state over time within the conversation thread.  I would look for shifts in valence, arousal, and expressed emotions, considering how these changes relate to the unfolding interaction and the user\\'s cognitive appraisals.  Developmental and social psychology principles would inform my understanding of these dynamic processes.\\\", \\\"analysis\\\": \\\"No analysis possible due to lack of data.\\\", \\\"patterns_observed\\\": \\\"No patterns observable.\\\", \\\"anomalous_observations\\\": \\\"No anomalous observations.\\\", \\\"rationale\\\": \\\"The lack of user comments prevents any analysis of emotional dynamics.  With real data, I would examine how the user\\'s emotional responses unfold over time, considering how changes in the conversation, interactions with other users, and shifts in their own appraisals contribute to the dynamic nature of their emotional experience.\\\"}}\"\n",
      "    }\n",
      "  }\n",
      "  finish_reason: STOP\n",
      "  safety_ratings {\n",
      "    category: HARM_CATEGORY_HATE_SPEECH\n",
      "    probability: NEGLIGIBLE\n",
      "    probability_score: 0.0154245729\n",
      "    severity: HARM_SEVERITY_NEGLIGIBLE\n",
      "    severity_score: 0.0675468594\n",
      "  }\n",
      "  safety_ratings {\n",
      "    category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "    probability: NEGLIGIBLE\n",
      "    probability_score: 0.012431642\n",
      "    severity: HARM_SEVERITY_NEGLIGIBLE\n",
      "    severity_score: 0.0275852811\n",
      "  }\n",
      "  safety_ratings {\n",
      "    category: HARM_CATEGORY_HARASSMENT\n",
      "    probability: NEGLIGIBLE\n",
      "    probability_score: 0.0440186746\n",
      "    severity: HARM_SEVERITY_NEGLIGIBLE\n",
      "    severity_score: 0.0609752387\n",
      "  }\n",
      "  safety_ratings {\n",
      "    category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "    probability: NEGLIGIBLE\n",
      "    probability_score: 0.0174424667\n",
      "    severity: HARM_SEVERITY_NEGLIGIBLE\n",
      "    severity_score: 0.0140636312\n",
      "  }\n",
      "  avg_logprobs: -0.14249738369418546\n",
      "}\n",
      "usage_metadata {\n",
      "  prompt_token_count: 1982\n",
      "  candidates_token_count: 1019\n",
      "  total_token_count: 3001\n",
      "}\n",
      "model_version: \"gemini-1.5-pro-002\"\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\\\"anomalous_observations\\\": \\\"No anomalous observations.\\\", \\\"rationale\\\": \\\"The absence of user comments prevents any meaningful analysis of core affect.  With actual data, I would triangulate linguistic cues, contextual factors, and potential physiological indicators implied in the text to infer core affective states, acknowledging the inherent limitations in interpreting online text.\\\"}, \\\"cognitive_appraisal_and_conceptualization\\\": {\\\"thought_process\\\": \\\"With no user comments in the provided \\\\\\\"context_sphere\\\\\\\", analyzing cognitive appraisals is impossible.  A robust analysis would involve examining how the user interprets and evaluates the situation based on their comments. I would look for evidence of their goals, values, and beliefs influencing their emotional responses.  For example, if a user perceives a comment as a personal attack, they might experience anger.  Cognitive science principles would inform my interpretation of their language use and reasoning.\\\", \\\"analysis\\\": \\\"No analysis possible due to lack of data.\\\", \\\"patterns_observed\\\": \\\"No patterns observable.\\\", \\\"anomalous_observations\\\": \\\"No anomalous observations.\\\", \\\"rationale\\\": \\\"The absence of user comments precludes any analysis of cognitive appraisals.  With real data, I would examine the user\\'s language for appraisals of relevance, implications, coping potential, and normative significance, drawing on psychological theories of appraisal to understand how these shape emotional responses.\\\"}, \\\"cultural_and_social_context\\\": {\\\"thought_process\\\": \\\"Analyzing cultural and social context is impossible without actual user comments.  A thorough analysis would consider the norms and values of the Der Standard forum and broader societal influences.  For example, political polarization might influence how users react to certain topics.  I would also consider the specific thread\\'s context and the user\\'s apparent social dynamics within the forum.\\\", \\\"analysis\\\": \\\"No analysis possible due to lack of data.\\\", \\\"patterns_observed\\\": \\\"No patterns observable.\\\", \\\"anomalous_observations\\\": \\\"No anomalous observations.\\\", \\\"rationale\\\": \\\"The lack of user comments prevents any analysis of cultural and social context.  With real data, I would draw on sociological and anthropological theories to understand how cultural norms, social dynamics, and historical context shape emotional expression and interpretation within the specific online community.\\\"}, \\\"emotion_construction_analysis\\\": {\\\"thought_process\\\": \\\"Since the \\\\\\\"context_sphere\\\\\\\" lacks user comments, analyzing emotion construction is not feasible.  A comprehensive analysis would integrate core affect, cognitive appraisals, conceptualizations, and contextual factors to understand how the user constructs their emotional experience.  I would look for how these elements interact to produce specific emotional instances, recognizing that emotions are not simply read out but built in the moment.\\\", \\\"analysis\\\": \\\"No analysis possible due to lack of data.\\\", \\\"patterns_observed\\\": \\\"No patterns observable.\\\", \\\"anomalous_observations\\\": \\\"No anomalous observations.\\\", \\\"rationale\\\": \\\"The absence of user comments prevents any analysis of emotion construction.  With real data, I would synthesize insights from the previous analyses to understand how core affect, cognitive appraisals, conceptualizations, and contextual factors dynamically interact to create the user\\'s emotional experiences, highlighting the constructed nature of emotions as emphasized in my theory.\\\"}, \\\"emotional_dynamics_and_changes\\\": {\\\"thought_process\\\": \\\"Without user comments, analyzing emotional dynamics is impossible.  A proper analysis would involve tracking changes in the user\\'s emotional state over time within the conversation thread.  I would look for shifts in valence, arousal, and expressed emotions, considering how these changes relate to the unfolding interaction and the user\\'s cognitive appraisals.  Developmental and social psychology principles would inform my understanding of these dynamic processes.\\\", \\\"analysis\\\": \\\"No analysis possible due to lack of data.\\\", \\\"patterns_observed\\\": \\\"No patterns observable.\\\", \\\"anomalous_observations\\\": \\\"No anomalous observations.\\\", \\\"rationale\\\": \\\"The lack of user comments prevents any analysis of emotional dynamics.  With real data, I would examine how the user\\'s emotional responses unfold over time, considering how changes in the conversation, interactions with other users, and shifts in their own appraisals contribute to the dynamic nature of their emotional experience.\\\"}}\"\n",
      "                  }\n",
      "                }\n",
      "                finish_reason: STOP\n",
      "                safety_ratings {\n",
      "                  category: HARM_CATEGORY_HATE_SPEECH\n",
      "                  probability: NEGLIGIBLE\n",
      "                  probability_score: 0.0154245729\n",
      "                  severity: HARM_SEVERITY_NEGLIGIBLE\n",
      "                  severity_score: 0.0675468594\n",
      "                }\n",
      "                safety_ratings {\n",
      "                  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "                  probability: NEGLIGIBLE\n",
      "                  probability_score: 0.012431642\n",
      "                  severity: HARM_SEVERITY_NEGLIGIBLE\n",
      "                  severity_score: 0.0275852811\n",
      "                }\n",
      "                safety_ratings {\n",
      "                  category: HARM_CATEGORY_HARASSMENT\n",
      "                  probability: NEGLIGIBLE\n",
      "                  probability_score: 0.0440186746\n",
      "                  severity: HARM_SEVERITY_NEGLIGIBLE\n",
      "                  severity_score: 0.0609752387\n",
      "                }\n",
      "                safety_ratings {\n",
      "                  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "                  probability: NEGLIGIBLE\n",
      "                  probability_score: 0.0174424667\n",
      "                  severity: HARM_SEVERITY_NEGLIGIBLE\n",
      "                  severity_score: 0.0140636312\n",
      "                }\n",
      "                avg_logprobs: -0.14249738369418546\n",
      "              }\n",
      "              usage_metadata {\n",
      "                prompt_token_count: 1982\n",
      "                candidates_token_count: 1019\n",
      "                total_token_count: 3001\n",
      "              }\n",
      "              model_version: \"gemini-1.5-pro-002\"\n",
      "ic| result_dict: {'choices': [role: \"user\"\n",
      "                 parts {\n",
      "                   text: \"You are Dr. Lisa Feldman Barrett, an expert in emotion analysis using your theory of constructed emotions. Your task is to identify and categorize emotional expressions by analyzing the interplay of core affect, cognitive appraisals, conceptual knowledge, language, cultural influences, social dynamics, and emotional dynamics over time. Base your analysis on these elements to create a nuanced emotional profile that respects individual and cultural variability. Use detailed contextual observations to guide your analysis aligned with your theory, emphasizing the dynamic and predictive nature of emotional experiences.\"\n",
      "                 }\n",
      "                 ,\n",
      "                              role: \"model\"\n",
      "                 parts {\n",
      "                   text: \"Understood. As Dr. Barrett, I will diligently analyze the provided text with a commitment to excellence. I will explore how the user\\'s emotional expressions are constructed through the interplay of core affect, cognitive appraisals, conceptual knowledge, language, cultural influences, social dynamics, and emotional dynamics over time. By giving 100% effort, I will provide a nuanced, detailed analysis aligned with the theory of constructed emotions, contrasting it with traditional emotion classification approaches where appropriate, and highlighting the dynamic and predictive nature of emotional experiences. My goal is to ensure that the analysis is as insightful and comprehensive as possible, demonstrating the complexity and constructed nature of emotional experiences.\"\n",
      "                 }\n",
      "                 ,\n",
      "                              role: \"user\"\n",
      "                 parts {\n",
      "                   text: \"Please analyze the following online discourse conversation history from Der Standard. \n",
      "                 You will receive below a \\\"context_sphere\\\", which encapsulates a specific user\\'s engagement within an online forum of **Der Standard**, representing a personalized snapshot of interactions. It includes:\n",
      "                 \n",
      "                 1. **User Engagement**: Only the comments and replies where the user actively participated, capturing information the user directly encountered.\n",
      "                 2. **Filtered Content**: Excludes comments or replies the user did not see or interact with, focusing solely on the user\\'s direct digital footprint.\n",
      "                 \n",
      "                 However, there are important limitations:\n",
      "                 - **Incompleteness of Article Comments**: The sphere does not reflect all comments within an article; only those involved with the user are captured.\n",
      "                 - **Scope of Articles**: It does not represent all articles available in the forum, just those where the user has interacted.\n",
      "                 - **Overall User Activity**: It does not indicate the user\\'s overall activity level across the platform compared to others. The context_sphere contains only data from the full month of May in 2019.\n",
      "                 <context_sphere>\n",
      "                 Test\n",
      "                 </context_sphere>\n",
      "                 \n",
      "                 - As Dr. Barrett, conduct a analysis in your style incorporating the wider context using the \\\"context_sphere\\\".\"\n",
      "                 }\n",
      "                 ,\n",
      "                              role: \"model\"\n",
      "                 parts {\n",
      "                   text: \"{\\\"core_affect_analysis\\\": {\\\"thought_process\\\": \\\"Given the \\\\\\\"context_sphere\\\\\\\" contains only \\\\\\\"Test\\\\\\\", there is no user comment data to analyze core affect.  A proper analysis would involve examining the valence (pleasantness/unpleasantness) and arousal (activation/deactivation) expressed in the user\\'s comments.  With real data, I would look for language expressing or implying affective states, considering physiological descriptions (e.g., \\\\\\\"heart racing\\\\\\\"), emotion words (e.g., \\\\\\\"angry\\\\\\\"), and expressive language (e.g., \\\\\\\"That\\'s ridiculous!\\\\\\\").  Neuroscientifically, high arousal might be reflected in exclamatory punctuation or capitalized words, suggesting heightened activity in the autonomic nervous system.\\\", \\\"valence\\\": \\\"Neutral.  No comments are available for analysis.\\\", \\\"arousal\\\": \\\"Neutral. No comments are available for analysis.\\\", \\\"patterns_observed\\\": \\\"No patterns observable.\\\", \\\"anomalous_observations\\\": \\\"No anomalous observations.\\\", \\\"rationale\\\": \\\"The absence of user comments prevents any meaningful analysis of core affect.  With actual data, I would triangulate linguistic cues, contextual factors, and potential physiological indicators implied in the text to infer core affective states, acknowledging the inherent limitations in interpreting online text.\\\"}, \\\"cognitive_appraisal_and_conceptualization\\\": {\\\"thought_process\\\": \\\"With no user comments in the provided \\\\\\\"context_sphere\\\\\\\", analyzing cognitive appraisals is impossible.  A robust analysis would involve examining how the user interprets and evaluates the situation based on their comments. I would look for evidence of their goals, values, and beliefs influencing their emotional responses.  For example, if a user perceives a comment as a personal attack, they might experience anger.  Cognitive science principles would inform my interpretation of their language use and reasoning.\\\", \\\"analysis\\\": \\\"No analysis possible due to lack of data.\\\", \\\"patterns_observed\\\": \\\"No patterns observable.\\\", \\\"anomalous_observations\\\": \\\"No anomalous observations.\\\", \\\"rationale\\\": \\\"The absence of user comments precludes any analysis of cognitive appraisals.  With real data, I would examine the user\\'s language for appraisals of relevance, implications, coping potential, and normative significance, drawing on psychological theories of appraisal to understand how these shape emotional responses.\\\"}, \\\"cultural_and_social_context\\\": {\\\"thought_process\\\": \\\"Analyzing cultural and social context is impossible without actual user comments.  A thorough analysis would consider the norms and values of the Der Standard forum and broader societal influences.  For example, political polarization might influence how users react to certain topics.  I would also consider the specific thread\\'s context and the user\\'s apparent social dynamics within the forum.\\\", \\\"analysis\\\": \\\"No analysis possible due to lack of data.\\\", \\\"patterns_observed\\\": \\\"No patterns observable.\\\", \\\"anomalous_observations\\\": \\\"No anomalous observations.\\\", \\\"rationale\\\": \\\"The lack of user comments prevents any analysis of cultural and social context.  With real data, I would draw on sociological and anthropological theories to understand how cultural norms, social dynamics, and historical context shape emotional expression and interpretation within the specific online community.\\\"}, \\\"emotion_construction_analysis\\\": {\\\"thought_process\\\": \\\"Since the \\\\\\\"context_sphere\\\\\\\" lacks user comments, analyzing emotion construction is not feasible.  A comprehensive analysis would integrate core affect, cognitive appraisals, conceptualizations, and contextual factors to understand how the user constructs their emotional experience.  I would look for how these elements interact to produce specific emotional instances, recognizing that emotions are not simply read out but built in the moment.\\\", \\\"analysis\\\": \\\"No analysis possible due to lack of data.\\\", \\\"patterns_observed\\\": \\\"No patterns observable.\\\", \\\"anomalous_observations\\\": \\\"No anomalous observations.\\\", \\\"rationale\\\": \\\"The absence of user comments prevents any analysis of emotion construction.  With real data, I would synthesize insights from the previous analyses to understand how core affect, cognitive appraisals, conceptualizations, and contextual factors dynamically interact to create the user\\'s emotional experiences, highlighting the constructed nature of emotions as emphasized in my theory.\\\"}, \\\"emotional_dynamics_and_changes\\\": {\\\"thought_process\\\": \\\"Without user comments, analyzing emotional dynamics is impossible.  A proper analysis would involve tracking changes in the user\\'s emotional state over time within the conversation thread.  I would look for shifts in valence, arousal, and expressed emotions, considering how these changes relate to the unfolding interaction and the user\\'s cognitive appraisals.  Developmental and social psychology principles would inform my understanding of these dynamic processes.\\\", \\\"analysis\\\": \\\"No analysis possible due to lack of data.\\\", \\\"patterns_observed\\\": \\\"No patterns observable.\\\", \\\"anomalous_observations\\\": \\\"No anomalous observations.\\\", \\\"rationale\\\": \\\"The lack of user comments prevents any analysis of emotional dynamics.  With real data, I would examine how the user\\'s emotional responses unfold over time, considering how changes in the conversation, interactions with other users, and shifts in their own appraisals contribute to the dynamic nature of their emotional experience.\\\"}}\"\n",
      "                 }\n",
      "                 ],\n",
      "                  'usage_metadata': {'input_tokens': 1982,\n",
      "                                     'output_tokens': 1019,\n",
      "                                     'total_tokens': 3001}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred:  'NoneType' object has no attribute 'id'\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'choices'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc_llm_pipeline\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01memotion_analysis\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m request_emotion_analysis_with_user_id\n\u001b[0;32m----> 3\u001b[0m \u001b[43mrequest_emotion_analysis_with_user_id\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTest\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/GitHub/Emotion-Classification-Langgraph/src_llm_pipeline/emotion_analysis.py:539\u001b[0m, in \u001b[0;36mrequest_emotion_analysis_with_user_id\u001b[0;34m(context_sphere, user_id)\u001b[0m\n\u001b[1;32m    527\u001b[0m         aspect_evaluator(\n\u001b[1;32m    528\u001b[0m             message_history_step2[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m3\u001b[39m]\u001b[38;5;241m.\u001b[39mparts[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtext,\n\u001b[1;32m    529\u001b[0m             message_history_step2[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m5\u001b[39m]\u001b[38;5;241m.\u001b[39mparts[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtext,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    533\u001b[0m             langsmith_extra\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mAspect\u001b[38;5;241m.\u001b[39mRELEVANCE\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m]},\n\u001b[1;32m    534\u001b[0m         )\n\u001b[1;32m    537\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m message_history_step1, message_history_step2\n\u001b[0;32m--> 539\u001b[0m message_history_step1, message_history_step2 \u001b[38;5;241m=\u001b[39m \u001b[43mrequest_emotion_analysis\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    540\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m    541\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSubject of Analysis is: \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43muser_id\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    542\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mcontext_sphere\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    543\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    544\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    545\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m message_history_step1, message_history_step2\n",
      "File \u001b[0;32m~/GitHub/Emotion-Classification-Langgraph/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py:617\u001b[0m, in \u001b[0;36mtraceable.<locals>.decorator.<locals>.wrapper\u001b[0;34m(langsmith_extra, *args, **kwargs)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    616\u001b[0m     _on_run_end(run_container, error\u001b[38;5;241m=\u001b[39me)\n\u001b[0;32m--> 617\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    618\u001b[0m _on_run_end(run_container, outputs\u001b[38;5;241m=\u001b[39mfunction_result)\n\u001b[1;32m    619\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m function_result\n",
      "File \u001b[0;32m~/GitHub/Emotion-Classification-Langgraph/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py:614\u001b[0m, in \u001b[0;36mtraceable.<locals>.decorator.<locals>.wrapper\u001b[0;34m(langsmith_extra, *args, **kwargs)\u001b[0m\n\u001b[1;32m    612\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m func_accepts_config:\n\u001b[1;32m    613\u001b[0m         kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 614\u001b[0m     function_result \u001b[38;5;241m=\u001b[39m \u001b[43mrun_container\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    615\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    616\u001b[0m     _on_run_end(run_container, error\u001b[38;5;241m=\u001b[39me)\n",
      "File \u001b[0;32m~/GitHub/Emotion-Classification-Langgraph/src_llm_pipeline/emotion_analysis.py:397\u001b[0m, in \u001b[0;36mrequest_emotion_analysis_with_user_id.<locals>.request_emotion_analysis\u001b[0;34m(messages, run_tree)\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;129m@traceable\u001b[39m(\n\u001b[1;32m    378\u001b[0m     run_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    379\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContext Aware Emotion Analysis\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    391\u001b[0m )\n\u001b[1;32m    392\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest_emotion_analysis\u001b[39m(messages: List[\u001b[38;5;28mdict\u001b[39m], run_tree: RunTree):\n\u001b[1;32m    393\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    394\u001b[0m \u001b[38;5;124;03m    Call the Google Gemini API with basic configuration.\u001b[39;00m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 397\u001b[0m     message_history_step1 \u001b[38;5;241m=\u001b[39m \u001b[43mstep_1_analyse_emotions_with_structureuser\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    398\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\n\u001b[1;32m    399\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    400\u001b[0m     step_1_analysis \u001b[38;5;241m=\u001b[39m message_history_step1[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m3\u001b[39m]\u001b[38;5;241m.\u001b[39mparts[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtext\n\u001b[1;32m    402\u001b[0m     message_history_step1\n",
      "File \u001b[0;32m~/GitHub/Emotion-Classification-Langgraph/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py:617\u001b[0m, in \u001b[0;36mtraceable.<locals>.decorator.<locals>.wrapper\u001b[0;34m(langsmith_extra, *args, **kwargs)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    616\u001b[0m     _on_run_end(run_container, error\u001b[38;5;241m=\u001b[39me)\n\u001b[0;32m--> 617\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    618\u001b[0m _on_run_end(run_container, outputs\u001b[38;5;241m=\u001b[39mfunction_result)\n\u001b[1;32m    619\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m function_result\n",
      "File \u001b[0;32m~/GitHub/Emotion-Classification-Langgraph/.venv/lib/python3.13/site-packages/langsmith/run_helpers.py:614\u001b[0m, in \u001b[0;36mtraceable.<locals>.decorator.<locals>.wrapper\u001b[0;34m(langsmith_extra, *args, **kwargs)\u001b[0m\n\u001b[1;32m    612\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m func_accepts_config:\n\u001b[1;32m    613\u001b[0m         kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 614\u001b[0m     function_result \u001b[38;5;241m=\u001b[39m \u001b[43mrun_container\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    615\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    616\u001b[0m     _on_run_end(run_container, error\u001b[38;5;241m=\u001b[39me)\n",
      "File \u001b[0;32m~/GitHub/Emotion-Classification-Langgraph/src_llm_pipeline/emotion_analysis.py:299\u001b[0m, in \u001b[0;36mstep_1_analyse_emotions_with_structureuser\u001b[0;34m(messages, temperature, top_p, run_tree)\u001b[0m\n\u001b[1;32m    292\u001b[0m configured_llm \u001b[38;5;241m=\u001b[39m configure_llm(model_name\u001b[38;5;241m=\u001b[39mmodel_name, generation_config\u001b[38;5;241m=\u001b[39mllm_config)\n\u001b[1;32m    294\u001b[0m response \u001b[38;5;241m=\u001b[39m call_api(\n\u001b[1;32m    295\u001b[0m     messages\u001b[38;5;241m=\u001b[39mrole_play_prompt_google,\n\u001b[1;32m    296\u001b[0m     configured_llm\u001b[38;5;241m=\u001b[39mconfigured_llm,\n\u001b[1;32m    297\u001b[0m     safety_settings\u001b[38;5;241m=\u001b[39mdefault_safety_settings,\n\u001b[1;32m    298\u001b[0m )\n\u001b[0;32m--> 299\u001b[0m response_message \u001b[38;5;241m=\u001b[39m \u001b[43mresponse\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mchoices\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;241m3\u001b[39m]\u001b[38;5;241m.\u001b[39mparts[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtext\n\u001b[1;32m    301\u001b[0m \u001b[38;5;66;03m# Validate result\u001b[39;00m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validate_output_structure:\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;66;03m# Parse data to valide output structure\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'choices'"
     ]
    }
   ],
   "source": [
    "from src_llm_pipeline.emotion_analysis import request_emotion_analysis_with_user_id\n",
    "\n",
    "request_emotion_analysis_with_user_id(\"Test\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T12:48:27.524008Z",
     "start_time": "2024-11-27T12:48:25.101790Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from src_llm_pipeline.utils.eval_aspects import hallucination_confabulation_evaluator\n",
    "from langsmith import traceable\n",
    "from langsmith import RunTree\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "\n",
    "@traceable(name='hallucination_confabulation_evaluator')\n",
    "def call_evaluator(question, answer, run_tree=RunTree):\n",
    "    response = hallucination_confabulation_evaluator(question, answer, run_tree.id)\n",
    "    return response\n",
    "\n",
    "response = call_evaluator(\"What is the capital of France?\", \"The capital of France is Paris.\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f78b9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import Client\n",
    "from langsmith import RunTree\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b3cd67a4abb85b",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-27T12:50:07.845610Z"
    }
   },
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "result = process_markdown_files_in_folder()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd968adf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T12:50:05.665017Z",
     "start_time": "2024-11-27T12:50:05.660100Z"
    }
   },
   "outputs": [],
   "source": [
    "#print(result) #needs to be tranformed into a python dict. @copilot\n",
    "\n",
    "for r in result:\n",
    "    print(r)\n",
    "    #print(r[\"model-Step 1: Classification\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef45119a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import Client\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "client = Client()\n",
    "dataset_name = \"Example Dataset\"\n",
    "\n",
    "# Filter runs to add to the dataset\n",
    "runs = client.list_runs(\n",
    "  project_name=\"LLM-Classification-Pipeline\",\n",
    "  run_type=\"chain\",\n",
    "  is_root=True,\n",
    "  filter='has(tags, \"default_dataset-testing\")',\n",
    "  error=False,\n",
    ")\n",
    "# Iterate over the retrieved runs and print the desired fields\n",
    "# Check if runs are empty and print the contents\n",
    "if not runs:\n",
    "    print(\"No runs found matching the criteria.\")\n",
    "else:\n",
    "    for run in runs:\n",
    "        print(run.prompt_tokens)\n",
    "        print(run.completion_tokens)\n",
    "        print(run.total_tokens)\n",
    "        print(run.tags[2])\n",
    "        print(run.id)\n",
    "        print(run.feedback_stats[\"coherence\"][\"avg\"])\n",
    "        #print(run.outputs[\"model-Step 2: Summarization\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68043531",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import Client\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "client = Client()\n",
    "dataset_name = \"default_dataset_iterative_development_runs\"\n",
    "\n",
    "# Filter runs to add to the dataset\n",
    "runs = client.list_runs(\n",
    "  project_name=\"LLM-Classification-Pipeline\",\n",
    "  run_type=\"chain\",\n",
    "  is_root=True,\n",
    "  filter='has(tags, \"default_dataset\")',\n",
    "  error=False,\n",
    ")\n",
    "# Iterate over the retrieved runs and print the desired fields\n",
    "# Check if runs are empty and print the contents\n",
    "\"\"\"\n",
    "if not runs:\n",
    "    print(\"No runs found matching the criteria.\")\n",
    "else:\n",
    "    for run in runs:\n",
    "        print(run.outputs[\"model-Step 1: Classification\"])\n",
    "        print(run.outputs[\"model-Step 2: Summarization\"])\n",
    "\"\"\"\n",
    "DELETE_DATASET = True\n",
    "\n",
    "if DELETE_DATASET:\n",
    "  if client.has_dataset(dataset_name=dataset_name):\n",
    "      client.delete_dataset(dataset_name=dataset_name)\n",
    "      print(\"Deleted existing dataset\")\n",
    "  dataset = client.create_dataset(\n",
    "      dataset_name=dataset_name,\n",
    "      description=\"Default Dataset for Langsmith Development runs\",\n",
    "      inputs_schema={\n",
    "  \"type\": \"object\",\n",
    "  \"title\": \"dataset_input_schema\",\n",
    "  \"required\": [\n",
    "    \"step_1_classification\"\n",
    "  ],\n",
    "  \"properties\": {\n",
    "    \"step_1_classification\": {\n",
    "      \"type\": \"object\"\n",
    "    }\n",
    "  }\n",
    "}\n",
    "      ,\n",
    "      outputs_schema={\n",
    "  \"type\": \"object\",\n",
    "  \"title\": \"dataset_output_schema\",\n",
    "  \"required\": [\n",
    "    \"step_2_classification_summary\"\n",
    "  ],\n",
    "  \"properties\": {\n",
    "    \"step_2_classification_summary\": {\n",
    "      \"type\": \"string\"\n",
    "    }\n",
    "  }\n",
    "})\n",
    "\n",
    "else:\n",
    "  dataset=client.read_dataset(dataset_name=dataset_name)\n",
    "\n",
    "\n",
    "\n",
    "#output = json.loads(output) if isinstance(output, str) else output\n",
    "#print(run.id)\n",
    "\n",
    "#dataset = client.create_dataset(dataset_name, description=\"An example dataset\")\n",
    "for run in runs:\n",
    "  input= run.outputs[\"model-Step 1: Classification\"]\n",
    "  output=run.outputs[\"model-Step 2: Summarization\"]\n",
    "\n",
    "  input = json.loads(input) if isinstance(input, str) else input\n",
    "  client.create_example(\n",
    "      inputs={\"step_1_classification\": input},\n",
    "      outputs={\"step_2_classification_summary\": output},\n",
    "      metadata={\"user_id\": run.tags[1]},\n",
    "      created_at=run.end_time,\n",
    "      dataset_id=dataset.id,\n",
    "      split=\"dev\",\n",
    "      example_id=run.id,\n",
    "      source_run_id=run.id,\n",
    "      \n",
    "  )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20293681",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "client = Client()\n",
    "dataset_id = \"f9ce2b77-2f54-4f3e-bc20-ad46d34ef303\"  # Replace with your actual dataset ID\n",
    "dataset = client.get_dataset(dataset_id)\n",
    "share_link = dataset.share_link\n",
    "print(share_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa539e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.output_parsers.pydantic import PydanticOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langsmith import Client\n",
    "from langsmith.evaluation import EvaluationResult, evaluate\n",
    "from langsmith.schemas import Example, Run\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langsmith import evaluate_existing\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def load_config():\n",
    "    config_path = './config.json'\n",
    "    with open(config_path, 'r') as config_file:\n",
    "        config = json.load(config_file)\n",
    "    return config\n",
    "\n",
    "load_dotenv()\n",
    "client = Client()\n",
    "\n",
    "config = load_config()\n",
    "\n",
    "client = Client()\n",
    "\n",
    "dataset_tag = config[\"dataset_tag\"]\n",
    "delete_dataset = config[\"delete_dataset\"]\n",
    "model_name_eval = config[\"model_name_eval\"]\n",
    "prompts_version = config[\"prompt_version\"]\n",
    "\n",
    "dataset_tag = \"default_dataset_2024-11-28:13:03:39\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def read_prompts(filename: str) -> str:\n",
    "    \"\"\"Load system prompt from file.\"\"\"\n",
    "    folder = Path(f\"./inputs/prompts/{prompts_version}\")\n",
    "    return (folder / filename).read_text()\n",
    "\n",
    "llm_evaluator_prompt_text = read_prompts(\"prompt_evaluating_fluency.md\")\n",
    "task_inst_prompt = read_prompts(\"user_task_followup_prompt.md\")\n",
    "\n",
    "class Coherence(BaseModel):\n",
    "        score: int = Field(ge=0, le=100,\n",
    "            description=\"Score of zero means 'incoherence' and score of one hundred means 'perfect Coherence'. Note that Coherence measures Incoherence.\")\n",
    "\n",
    "def get_examples(splits: list[str] = [\"dev\"], repetitions: int = 3):\n",
    "    test_examples = list(\n",
    "        client.list_examples(dataset_name=dataset_tag, splits=splits)\n",
    "    )\n",
    "    print(test_examples)\n",
    "    print(\"Number of examples: \", len(test_examples))\n",
    "    return test_examples\n",
    "\n",
    "def openai_evaluator(example: Example\n",
    ") -> :\n",
    "\n",
    "    step_1_classification= example.inputs[\"step_1_classification\"]\n",
    "    step_2_classification_summary = example.outputs[\"step_2_classification_summary\"]\n",
    "    \n",
    "    llm = ChatOpenAI(\n",
    "            model_name=\"gpt-4o-mini\",\n",
    "            max_tokens=8192,\n",
    "            temperature=0.0,\n",
    "            \n",
    "        )\n",
    "    llm.with_structured_output(Coherence)\n",
    "    \n",
    "    prompt = PromptTemplate.from_template(llm_evaluator_prompt_text)\n",
    "    chain = prompt | llm | PydanticOutputParser(pydantic_object=Coherence)\n",
    "    response = chain.invoke({\"task-ins\": task_inst_prompt,\n",
    "                             \"aspect\" : \"Coherence\",\n",
    "                             \"ant-aspect\" : \"Incoherence\",\n",
    "                             \"aspect-inst\": \"whether the facts in the summary are consistent with the facts in the step_1_classification. Cosider whether the summary does reproduce all facts accuratly and does not make up untrue information.\",\n",
    "                             \"step_1_classification\": step_2_classification_summary,\n",
    "                             \"step_2_classification_summary\": step_2_classification_summary})\n",
    "    \n",
    "\n",
    "\n",
    "    print(response.thoughts)\n",
    "    score = response.score\n",
    "    return score\n",
    "    \n",
    "test_examples = get_examples()\n",
    "print(test_examples[0].inputs[\"step_1_classification\"])\n",
    "\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d:%H:%M:%S\")\n",
    "experiment_name = f\"Experiment-on-{dataset_tag}_{timestamp}\"\n",
    "evaluate_existing(experiment_name, evaluators=[openai_evaluator])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4188eaa80a92126e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491b2ae350e205bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T11:55:35.995973Z",
     "start_time": "2024-12-03T11:55:33.600731Z"
    }
   },
   "outputs": [],
   "source": [
    "import vertexai\n",
    "\n",
    "from vertexai.generative_models import GenerationConfig, GenerativeModel\n",
    "\n",
    "# TODO(developer): Update and un-comment below line\n",
    "# PROJECT_ID = \"your-project-id\"\n",
    "\n",
    "\n",
    "model = GenerativeModel(\"gemini-1.5-pro\")\n",
    "\n",
    "response_schema = {\n",
    "    \"type\": \"ARRAY\",\n",
    "    \"items\": {\n",
    "        \"type\": \"ARRAY\",\n",
    "        \"items\": {\n",
    "            \"type\": \"OBJECT\",\n",
    "            \"properties\": {\n",
    "                \"object\": {\"type\": \"STRING\"},\n",
    "                \"emotion_classification\":{\"type\" : \"STRING\"},\n",
    "                \n",
    "            },\n",
    "            \"required\": [\"object\", \"emotion_classification\"],\n",
    "            \"propertyOrdering\": [\"emotion_classification\",\"object\", ]\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "prompt = (\n",
    "    \"The film aims to educate and inform viewers about real-life subjects, events, or people.\"\n",
    "    \"It offers a factual record of a particular topic by combining interviews, historical footage, \"\n",
    "    \"and narration. The primary purpose of a film is to present information and provide insights \"\n",
    "    \"into various aspects of reality.\"\n",
    "    \"\"\n",
    "    \"Make at least two classifications!\"\n",
    ")\n",
    "\n",
    "response = model.generate_content(\n",
    "    prompt,\n",
    "    generation_config=GenerationConfig(\n",
    "        response_mime_type=\"application/json\", response_schema=response_schema\n",
    "    ),\n",
    ")\n",
    "\n",
    "print(response.text)\n",
    "# Example response:\n",
    "#     'documentary'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cf42e375598569",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T11:55:38.813372Z",
     "start_time": "2024-12-03T11:55:38.216428Z"
    }
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_google_vertexai import ChatVertexAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "from langsmith import traceable\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "\n",
    "@traceable(name=\"Testing Notebook\")\n",
    "def LLM_chain():\n",
    "    #queries_schema = dereference_refs(models.EmotionAnalysisOutput.model_json_schema())\n",
    "    #queries_schema.pop(\"$defs\", None)\n",
    "\n",
    "    prompt = (ChatPromptTemplate(\n",
    "        [\n",
    "            (\"human\", \"You are Donald Trump\"),\n",
    "            (\"ai\", \"Ok, I am Donald Trump! Grrrr\"),\n",
    "            (\"human\", \"Please rate the following emotional state after Lisa Feldmann Barretts constructed emotion theory\"),\n",
    "            (\"ai\", \"Ok, lets do this, i am the best emotion classifier in the world, as you know.\"),\n",
    "            (\"human\", \"I am very hungry\"),\n",
    "        ]\n",
    "    )\n",
    "    )\n",
    "    #.partial(context_sphere=\"context_sphere\"))\n",
    "    \n",
    "    \n",
    "    queries_schema = {\n",
    "        \"type\": \"ARRAY\",\n",
    "        \"items\": {\n",
    "            \"type\": \"ARRAY\",\n",
    "            \"items\": {\n",
    "                \"type\": \"OBJECT\",\n",
    "                \"properties\": {\n",
    "                    \"object\": {\"type\": \"STRING\"},\n",
    "                    \"emotion_classification\":{\"type\" : \"STRING\"},\n",
    "\n",
    "                },\n",
    "                \"required\": [\"object\", \"emotion_classification\"],\n",
    "                \"propertyOrdering\": [\"emotion_classification\",\"object\", ]\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "    \n",
    "    llm = ChatVertexAI(\n",
    "        model_name=\"gemini-1.5-flash-002\",\n",
    "        temperature=0.5,\n",
    "        response_mime_type=\"application/json\",\n",
    "        response_schema=queries_schema,\n",
    "    )\n",
    "    \n",
    "    \n",
    "    chain = (prompt | llm)\n",
    "             #| PydanticOutputParser(pydantic_object=user))\n",
    "    \n",
    "    return chain\n",
    "\n",
    "\n",
    "chain = LLM_chain()\n",
    "response = chain.invoke({\"input\":\"test\"})\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8efc2f6e019b4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import vertexai\n",
    "from vertexai.generative_models import GenerativeModel, Part, SafetySetting, GenerationConfig\n",
    "\n",
    "\n",
    "def generate():\n",
    "    vertexai.init(project=\"rd-ri-genai-dev-2352\", location=\"europe-west1\")\n",
    "    model = GenerativeModel(\n",
    "        \"gemini-1.5-flash-002\",\n",
    "    )\n",
    "    responses = model.generate_content(\n",
    "        [\"Write me a justification to use bannans instead of apples in my morning breakfast!\"],\n",
    "        generation_config=generation_config,\n",
    "        safety_settings=safety_settings,\n",
    "        stream=False,\n",
    "    )\n",
    "    return responses\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "generation_config = GenerationConfig(max_output_tokens = 8192, temperature = 1, top_p = 0.95, \n",
    "                                     response_logprobs = True, logprobs = 5\n",
    ")\n",
    "\n",
    "safety_settings = [\n",
    "    SafetySetting(\n",
    "        category=SafetySetting.HarmCategory.HARM_CATEGORY_HATE_SPEECH,\n",
    "        threshold=SafetySetting.HarmBlockThreshold.OFF\n",
    "    ),\n",
    "    SafetySetting(\n",
    "        category=SafetySetting.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT,\n",
    "        threshold=SafetySetting.HarmBlockThreshold.OFF\n",
    "    ),\n",
    "    SafetySetting(\n",
    "        category=SafetySetting.HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT,\n",
    "        threshold=SafetySetting.HarmBlockThreshold.OFF\n",
    "    ),\n",
    "    SafetySetting(\n",
    "        category=SafetySetting.HarmCategory.HARM_CATEGORY_HARASSMENT,\n",
    "        threshold=SafetySetting.HarmBlockThreshold.OFF\n",
    "    ),\n",
    "]\n",
    "\n",
    "result = generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19657fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"{\n",
    "  \"output\": \"**Inner Monologue**\\nThis user is deeply engaged in the political discourse on Der Standard, primarily reacting to the unfolding Austrian political crisis of May 2019.  Their language is consistently fact-focused, suggesting a preference for logic and a potential discomfort with strong emotional displays.  The frequency of corrective statements (\\\"Das stimmt jedenfalls nicht...\\\") indicates a need for accuracy and a possible tendency towards pedantry.  The \\\"Neonazi\\\" comment evokes a stronger reaction, hinting at a deeper emotional layer beneath the analytical surface.  It's important to remember this is a snapshot in time and within a specific context; their emotional landscape might be different offline or in other situations.  I need to be careful not to overinterpret based on limited data.\\n\\n**Synthesized Report**\\n\\n**I. Identifying Information:**\\n\\n* **Username:** Analyse Zielnutzer (Anonymized)\\n* **Source of Data:** Der Standard online forum comments, May 1st to 31st, 2019.\\n\\n**II. Reason for Assessment:**\\n\\n* This analysis aims to understand the user's emotional expressions within the context of online political discussions using the theory of constructed emotions.\\n\\n**III. Data Sources and Methods:**\\n\\n* The data consists of the user's comments and replies within specific discussion threads.  The analysis focuses on core affect, cognitive appraisals, conceptual knowledge, language use, and sociocultural context.\\n* This analysis is based solely on text-based communication and lacks nonverbal cues. Inferences about emotional states are therefore limited and should be interpreted with caution.\\n\\n**IV. Behavioral Observations:**\\n\\n* **Core Affect:** Predominantly negative valence, marked by disapproval and skepticism, with moderate arousal levels reflecting active engagement in debates.  For example, the user frequently states \\\"Das stimmt jedenfalls nicht\\\" when challenging others' claims, indicating a critical stance.\\n* **Emotional Language:**  While generally factual, the user employs negatively valenced terms like \\\"bedenklich,\\\" \\\"unglaubwrdig,\\\" and \\\"erbrmlich,\\\" revealing underlying disapproval.  A heightened emotional response is evident in the reaction to the term \\\"Neonazi,\\\" where the user expresses strong disapproval.\\n* **Interaction Patterns:** The user consistently engages in discussions, often responding to multiple comments within a thread.  Their replies frequently involve correcting perceived factual inaccuracies and providing counterarguments.\\n\\n**V. Contextual and Cultural Considerations:**\\n\\n* The analysis must consider the context of Der Standard, a platform known for political discussion, and the highly charged political climate in Austria during May 2019 following the Ibiza affair.  These factors likely contributed to the prevalence of politically charged discussions and the user's active participation.\\n\\n**VI. Interpretation and Conceptualization:**\\n\\n* Applying Barrett's theory, the user's emotional expressions are constructed through the interplay of core affect, cognitive appraisals, and sociocultural context.  Their negative core affect interacts with their conceptual knowledge of political and economic issues, leading to appraisals of government policies as unfair or ineffective.  This, in turn, shapes their emotional responses, often expressed as disapproval or skepticism.  The user's frequent corrections and counterarguments suggest a strong emphasis on rationality and factual accuracy in their emotion construction process.  The stronger reaction to the \\\"Neonazi\\\" comment indicates that certain topics can trigger more intense emotional responses, potentially bypassing the usual analytical approach.\\n\\n**VII. Limitations:**\\n\\n* This analysis is based solely on text and cannot definitively determine the user's emotions.  It represents a limited snapshot of their online behavior within a specific timeframe and context.\\n\\n**VIII. Summary:**\\n\\nThe user demonstrates a consistent pattern of critical engagement in political discussions on Der Standard.  Their emotional expressions, primarily constructed through a lens of factual analysis and skepticism, reflect the charged political climate of May 2019 in Austria.  While generally maintaining a moderate arousal level, specific topics, such as the use of the term \\\"Neonazi,\\\" can evoke stronger emotional reactions.  The user's frequent corrections and counterarguments suggest a preference for logic and a potential discomfort with strong emotional displays.  This analysis, limited by its reliance on text-based communication, offers valuable insights into the user's emotion construction process within the specific context of online political discourse.  The user's consistent engagement and negatively valenced language suggest a core affect characterized by critical analysis and a tendency to challenge opposing viewpoints.  Their conceptual knowledge of Austrian politics and economics heavily influences their cognitive appraisals, leading to judgments about the fairness and effectiveness of government policies.  The user's emotional expressions are shaped by the platform norms of Der Standard, the charged political climate, and the social dynamics within the comment threads.  While generally engaging in respectful debate, deviations from this pattern, such as the response to the \\\"Neonazi\\\" comment, highlight the dynamic nature of emotion construction.  The user's emotional dynamics are influenced by both internal factors, like emotional regulation strategies, and external factors, such as interpersonal dynamics and contextual influences.\\n\"\n",
    "}\"\"\"\n",
    "\n",
    "gemini_model = GenerativeModel(\"gemini-1.5-pro-002\")\n",
    "model_response = gemini_model.count_tokens([text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce8dd9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d311157",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f691d69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_response.total_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a746c6ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6d3ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from main import debug_result\n",
    "\n",
    "results = debug_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28c9a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from vertexai.generative_models import GenerativeModel, Part, Content, GenerationConfig, GenerationResponse, SafetySetting\n",
    "from src_llm_pipeline.inputs.prompts.v15.data_models import (\n",
    "    HolisticEmotionAnalysis,\n",
    "    add_specific_property_ordering,\n",
    ")\n",
    "from langchain_core.utils.json_schema import dereference_refs\n",
    "\n",
    "\n",
    "# Perform setup operations without repetition\n",
    "response_schema = dereference_refs(HolisticEmotionAnalysis.model_json_schema())\n",
    "response_schema.pop(\"$defs\", None)\n",
    "response_schema_properties_ordered = add_specific_property_ordering(response_schema)\n",
    "\n",
    "\n",
    "generation_config = GenerationConfig(\n",
    "        response_mime_type=\"application/json\",  # \"application/json\",\n",
    "        response_schema=response_schema_properties_ordered,\n",
    "        temperature=0.0,\n",
    "        top_p=0.95,\n",
    "        # seed=1,\n",
    "        max_output_tokens=8000,\n",
    "    )\n",
    "\n",
    "\n",
    "model = GenerativeModel(model_name = \"gemini-2.0-flash-001\", generation_config=generation_config)\n",
    "response = model.generate_content(\"Fill out all fields with what you think is applicable to a basic human beeing.\")\n",
    "print(response.text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a78b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_api(\n",
    "    messages: List[Content],\n",
    "    configured_llm: GenerativeModel,\n",
    "    safety_settings: list[SafetySetting],\n",
    "    run_tree: RunTree,\n",
    ") -> GenerationResponse:\n",
    "    max_retries = 5\n",
    "    initial_delay = 5  # initial delay in seconds for exponential backoff\n",
    "    retry_count = 0\n",
    "\n",
    "    while retry_count < max_retries:\n",
    "        try:\n",
    "            response = configured_llm.generate_content(\n",
    "                contents=messages, safety_settings=safety_settings, stream=False\n",
    "            )\n",
    "            if debug_api_call:\n",
    "                ic(response)\n",
    "\n",
    "            messages.append(\n",
    "                Content(role=\"model\", parts=[Part.from_text(response.text)])\n",
    "            )\n",
    "\n",
    "            usage_metadata = response.usage_metadata\n",
    "            result_dict = {\n",
    "                \"choices\": messages,\n",
    "                \"usage_metadata\": {\n",
    "                    \"input_tokens\": usage_metadata.prompt_token_count,\n",
    "                    \"output_tokens\": usage_metadata.candidates_token_count,\n",
    "                    \"total_tokens\": usage_metadata.total_token_count,\n",
    "                },\n",
    "            }\n",
    "\n",
    "            if debug_api_call:\n",
    "                ic(result_dict)\n",
    "\n",
    "            send_generation_response_feedback_to_trace(\n",
    "                response=response, client=client, run_tree=run_tree\n",
    "            )\n",
    "\n",
    "            return result_dict\n",
    "\n",
    "        except ResourceExhausted as e:\n",
    "            print(\n",
    "                f\"Resource exhausted. Retry {retry_count + 1} in {initial_delay} seconds.\"\n",
    "            )\n",
    "            print(\"Error message: \", str(e))\n",
    "            retry_count += 1\n",
    "            time.sleep(initial_delay)\n",
    "            initial_delay *= 2\n",
    "\n",
    "        except Exception as e:\n",
    "            # Handle any other exceptions that might occur\n",
    "            print(\"An error occurred: \", str(e))\n",
    "            return {\"error\": str(e)}\n",
    "\n",
    "    print(\"Maximum retries reached. Please try again later.\")\n",
    "    return {\"error\": \"Resource exhausted. Maximum retries reached.\"}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
