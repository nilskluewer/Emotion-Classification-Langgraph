{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-23T08:36:36.931303Z",
     "start_time": "2024-08-23T08:36:36.923288Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "import os\n",
    "import json\n",
    "from typing import List, Dict\n",
    "\n",
    "\n",
    "\n",
    "class DataPreprocessor:\n",
    "    def __init__(self, file_path: str):\n",
    "        \"\"\"\n",
    "        Initialize the DataPreprocessor with the file path.\n",
    "\n",
    "        Args:\n",
    "            file_path (str): The path to the CSV file containing the data.\n",
    "        \"\"\"\n",
    "        self.file_path = file_path\n",
    "        self.df = None\n",
    "\n",
    "    def process(self):\n",
    "        \"\"\"\n",
    "        Process the data by loading it from the CSV file and applying various preprocessing steps.\n",
    "        \"\"\"\n",
    "        self.df = pd.read_csv(self.file_path)\n",
    "        self._convert_dates()\n",
    "        self._handle_missing_values()\n",
    "        self._convert_id_columns()\n",
    "        self._create_new_features()\n",
    "\n",
    "    def _convert_dates(self):\n",
    "        \"\"\"\n",
    "        Convert date columns to datetime format.\n",
    "        \"\"\"\n",
    "        date_columns = ['PostingCreatedAt', 'ArticlePublishingDate', 'UserCreatedAt']\n",
    "        for col in date_columns:\n",
    "            self.df[col] = pd.to_datetime(self.df[col])\n",
    "\n",
    "    def _handle_missing_values(self):\n",
    "        \"\"\"\n",
    "        Handle missing values in the data by filling them with appropriate values.\n",
    "        \"\"\"\n",
    "        self.df['PostingHeadline'] = self.df['PostingHeadline'].fillna('No Headline')\n",
    "        self.df['PostingComment'] = self.df['PostingComment'].fillna('No Comment')\n",
    "        self.df['UserGender'] = self.df['UserGender'].fillna('Unknown')\n",
    "        self.df['UserCommunityName'] = self.df['UserCommunityName'].fillna('Unknown')\n",
    "\n",
    "    def _convert_id_columns(self):\n",
    "        \"\"\"\n",
    "        Convert ID columns to integer type.\n",
    "        \"\"\"\n",
    "        id_columns = ['ID_Posting', 'ID_Posting_Parent', 'ID_CommunityIdentity', 'ID_Article']\n",
    "        for col in id_columns:\n",
    "            self.df[col] = self.df[col].fillna(0).astype(int)\n",
    "\n",
    "    def _create_new_features(self):\n",
    "        \"\"\"\n",
    "        Create new features based on existing columns.\n",
    "        \"\"\"\n",
    "        self.df['CommentLength'] = self.df['PostingComment'].str.len()\n",
    "        self.df['DaysSinceUserCreation'] = (self.df['PostingCreatedAt'] - self.df['UserCreatedAt']).dt.days\n",
    "        self.df['IsReply'] = self.df['ID_Posting_Parent'] != 0\n",
    "        self.df['PostingHour'] = self.df['PostingCreatedAt'].dt.hour\n",
    "        self.df['PostingDayOfWeek'] = self.df['PostingCreatedAt'].dt.dayofweek\n",
    "\n",
    "    def save_preprocessed_data(self, output_path: str):\n",
    "        \"\"\"\n",
    "        Save the preprocessed data to a pickle file.\n",
    "\n",
    "        Args:\n",
    "            output_path (str): The path where the preprocessed data will be saved.\n",
    "        \"\"\"\n",
    "        with open(output_path, 'wb') as f:\n",
    "            pickle.dump(self.df, f)\n",
    "        print(f\"Preprocessed data saved to {output_path}\")\n",
    "\n",
    "    @classmethod\n",
    "    def load_preprocessed_data(cls, input_path: str):\n",
    "        \"\"\"\n",
    "        Load the preprocessed data from a pickle file.\n",
    "\n",
    "        Args:\n",
    "            input_path (str): The path to the pickle file containing the preprocessed data.\n",
    "\n",
    "        Returns:\n",
    "            DataPreprocessor: An instance of DataPreprocessor with the loaded data.\n",
    "        \"\"\"\n",
    "        with open(input_path, 'rb') as f:\n",
    "            df = pickle.load(f)\n",
    "        preprocessor = cls(None)\n",
    "        preprocessor.df = df\n",
    "        print(f\"Preprocessed data loaded from {input_path}\")\n",
    "        return preprocessor\n",
    "\n",
    "class CommentThreadManager:\n",
    "    def __init__(self, df: pd.DataFrame):\n",
    "        \"\"\"\n",
    "        Initialize the CommentThreadManager with the preprocessed data.\n",
    "\n",
    "        Args:\n",
    "            df (pd.DataFrame): The preprocessed data containing comment information.\n",
    "        \"\"\"\n",
    "        self.df = df\n",
    "\n",
    "    def build_comment_thread(self, comments: pd.DataFrame, parent_id: int) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Build a hierarchical structure of comments and their replies.\n",
    "\n",
    "        Args:\n",
    "            comments (pd.DataFrame): The comments data for a specific article.\n",
    "            parent_id (int): The ID of the parent comment.\n",
    "\n",
    "        Returns:\n",
    "            List[Dict]: A list of dictionaries representing the comment thread.\n",
    "        \"\"\"\n",
    "        replies = comments[comments['ID_Posting_Parent'] == parent_id]\n",
    "        return [{\n",
    "            'id': int(reply['ID_Posting']),\n",
    "            'parent_id': int(reply['ID_Posting_Parent']) if pd.notnull(reply['ID_Posting_Parent']) else None,\n",
    "            'user_id': int(reply['ID_CommunityIdentity']),\n",
    "            'user_name': reply['UserCommunityName'],\n",
    "            'user_gender': reply['UserGender'],\n",
    "            'user_created_at': reply['UserCreatedAt'].isoformat() if pd.notnull(reply['UserCreatedAt']) else None,\n",
    "            'comment_headline': reply['PostingHeadline'],\n",
    "            'comment_text': reply['PostingComment'],\n",
    "            'comment_created_at': reply['PostingCreatedAt'].isoformat() if pd.notnull(reply['PostingCreatedAt']) else None,\n",
    "            'comment_length': int(reply['CommentLength']),\n",
    "            'article_id': int(reply['ID_Article']),\n",
    "            'article_publish_date': reply['ArticlePublishingDate'].isoformat() if pd.notnull(reply['ArticlePublishingDate']) else None,\n",
    "            'article_title': reply['ArticleTitle'],\n",
    "            'article_channel': reply['ArticleChannel'],\n",
    "            'article_ressort_name': reply['ArticleRessortName'],\n",
    "            'replies': self.build_comment_thread(comments, int(reply['ID_Posting']))\n",
    "        } for _, reply in replies.iterrows()]\n",
    "\n",
    "    def get_article_threads(self) -> Dict[int, Dict]:\n",
    "        \"\"\"\n",
    "        Get the comment threads for all articles.\n",
    "\n",
    "        Returns:\n",
    "            Dict[int, Dict]: A dictionary where keys are article IDs and values are dictionaries representing the article's comment threads.\n",
    "        \"\"\"\n",
    "        articles = {}\n",
    "        for article_id, article_df in self.df.groupby('ID_Article'):\n",
    "            root_comments = article_df[article_df['ID_Posting_Parent'].isnull() | (article_df['ID_Posting_Parent'] == 0)]\n",
    "            threads = self.build_comment_thread(article_df, 0)\n",
    "            article_meta = article_df.iloc[0]\n",
    "\n",
    "            articles[int(article_id)] = {\n",
    "                'article_id': int(article_id),\n",
    "                'article_title': article_meta['ArticleTitle'],\n",
    "                'article_publish_date': article_meta['ArticlePublishingDate'].isoformat() if pd.notnull(article_meta['ArticlePublishingDate']) else None,\n",
    "                'article_channel': article_meta['ArticleChannel'],\n",
    "                'article_ressort_name': article_meta['ArticleRessortName'],\n",
    "                'total_comments': len(article_df),\n",
    "                'root_comments': len(root_comments),\n",
    "                'comment_threads': threads\n",
    "            }\n",
    "        return articles\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T08:42:44.876930Z",
     "start_time": "2024-08-23T08:36:41.723351Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Main execution\n",
    "preprocessed_file = r\"../data/preprocessed/preprocessed_data.pkl\"\n",
    "\n",
    "if not os.path.exists(preprocessed_file):\n",
    "    print(\"Preprocessed data not found. Preprocessing...\")\n",
    "    preprocessor = DataPreprocessor('../data/raw_csv/Postings_01052019_31052019.csv')\n",
    "    preprocessor.process()\n",
    "    preprocessor.save_preprocessed_data(preprocessed_file)\n",
    "else:\n",
    "    print(\"Loading preprocessed data...\")\n",
    "    preprocessor = DataPreprocessor.load_preprocessed_data(preprocessed_file)\n",
    "\n",
    "thread_manager = CommentThreadManager(preprocessor.df)\n",
    "articles_with_threads = thread_manager.get_article_threads()\n",
    "\n",
    "# Save the comprehensive data structure to a JSON file\n",
    "output_path = \"spheres/articles_with_threads_full_tree.json\"\n",
    "with open(output_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(articles_with_threads, f, indent=2)\n",
    "print(f\"Comprehensive data structure saved to {output_path}\")"
   ],
   "id": "75c5abf28c31b86c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading preprocessed data...\n",
      "Preprocessed data loaded from ../data/preprocessed/preprocessed_data.pkl\n",
      "Comprehensive data structure saved to articles_with_threads.json\n"
     ]
    }
   ],
   "execution_count": 4
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
