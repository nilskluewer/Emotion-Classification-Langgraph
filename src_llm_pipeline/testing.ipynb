{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T12:48:27.524008Z",
     "start_time": "2024-11-27T12:48:25.101790Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'description': 'Do not be lazy while working on your tasks!', 'properties': {'thought_process': {'description': \"Go step-by-step through your previous analysis, picking out the most influencal points for a nuanced classification.Focus on capturing unique emotional patterns specific to the user's behavior, avoiding generic statements that could apply to anyone. Utilize specific examples from the user's comments to highlight key emotional tendencies.\", 'title': 'Thought Process', 'type': 'string'}, 'nuanced_classification': {'description': \"Provide a nuanced classification based on prior analysis, ensuring the identification of distinct emotionalexpressions unique to the user. Avoid universal characterizations that lack specificity. Use emotion labels appropriately, acknowledging their dependency on context, and back your classification with precise examples from the user's comments.\", 'title': 'Nuanced Classification', 'type': 'string'}, 'discussion_behaviour': {'description': \"Analyze and describe the user's discussion behavior, focusing on how they express emotions and interact in conversational contexts.\", 'title': 'Discussion Behaviour', 'type': 'string'}}, 'required': ['thought_process', 'nuanced_classification', 'discussion_behaviour'], 'title': 'HolisticEmotionalProfile', 'type': 'object', 'propertyOrdering': ['thought_process', 'nuanced_classification', 'discussion_behaviour']}\n"
     ]
    }
   ],
   "source": [
    "from llm_call import process_markdown_files_in_folder\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60b3cd67a4abb85b",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-27T12:50:07.845610Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Start of User Processing ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START ANALYSIS OF USER:  8177\n",
      "Output matches schema ordering exactly!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files: 1it [00:31, 31.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START ANALYSIS OF USER:  19792\n",
      "Output matches schema ordering exactly!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files: 2it [01:04, 32.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- End of User Processing ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "\n",
    "\n",
    "random_uuid = uuid.uuid4()\n",
    "result = process_markdown_files_in_folder(batch_id=random_uuid, dataset_name = \"Testing\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd968adf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T12:50:05.665017Z",
     "start_time": "2024-11-27T12:50:05.660100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The user's emotional expressions online are dynamically constructed, reflecting interplay between core affect, cognitive appraisals, and sociocultural context.  Initial responses to the Semenya case exhibited high negative valence and arousal, stemming from appraisals of injustice and perceived threats to fairness in women's sports.  These reactions were tempered by later attempts at rule-based solutions, suggesting a shift towards more controlled emotional regulation.  However, high arousal persisted in interactions involving significant disagreement or controversial topics.  Comments on disaster preparedness showed a different emotional profile, characterized by increasing anxiety and a focus on practical concerns.  Overall, the user demonstrates emotional reactivity, influenced by the online forum’s dynamics and their existing beliefs, reflecting a complex and context-dependent emotional construction process.  A binary understanding of gender appears prevalent in their initial framing of the Semenya case, though not entirely exclusive.  Their communication style demonstrates an engagement with Austrian political and social issues, influencing the expression and shaping of their emotions.\n",
      "\n",
      "The user's emotional expressions on Der Standard demonstrate a dynamic interplay of fluctuating valence and arousal.  Negative valence arises from cynical appraisals of Austrian politics, particularly concerning the FPÖ and ÖVP, and perceived media bias, resulting in frustration, anger, and disgust.  Positive valence emerges from irony, amusement, and satisfaction derived from events aligning with personal expectations, particularly regarding sports.  High arousal is frequent during discussions on emotionally charged topics; however, the user often displays emotional regulation through sarcasm and detached observation.  The user's emotional experience is deeply rooted in their understanding of the Austrian socio-political context and reflects the ongoing national debate, demonstrating a constructed emotional profile influenced by cognitive appraisals, cultural norms, and social dynamics within the online community.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#print(result) #needs to be tranformed into a python dict. @copilot\n",
    "\n",
    "for r in result:\n",
    "    #print(r)\n",
    "    print(r[\"model-Step 2: Summarization\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ef45119a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-27 13:07:11.167889\n",
      "2024-11-27 13:06:44.652491\n"
     ]
    }
   ],
   "source": [
    "from langsmith import Client\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "client = Client()\n",
    "dataset_name = \"Example Dataset\"\n",
    "\n",
    "# Filter runs to add to the dataset\n",
    "runs = client.list_runs(\n",
    "  project_name=\"LLM-Classification-Pipeline\",\n",
    "  run_type=\"chain\",\n",
    "  is_root=True,\n",
    "  filter='has(tags, \"default_dataset\")',\n",
    "  error=False,\n",
    ")\n",
    "# Iterate over the retrieved runs and print the desired fields\n",
    "# Check if runs are empty and print the contents\n",
    "if not runs:\n",
    "    print(\"No runs found matching the criteria.\")\n",
    "else:\n",
    "    for run in runs:\n",
    "        print(run.end_time)\n",
    "        #print(run.outputs[\"model-Step 2: Summarization\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68043531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted existing dataset\n"
     ]
    }
   ],
   "source": [
    "from langsmith import Client\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "client = Client()\n",
    "dataset_name = \"default_dataset_iterative_development_runs\"\n",
    "\n",
    "# Filter runs to add to the dataset\n",
    "runs = client.list_runs(\n",
    "  project_name=\"LLM-Classification-Pipeline\",\n",
    "  run_type=\"chain\",\n",
    "  is_root=True,\n",
    "  filter='has(tags, \"default_dataset\")',\n",
    "  error=False,\n",
    ")\n",
    "# Iterate over the retrieved runs and print the desired fields\n",
    "# Check if runs are empty and print the contents\n",
    "\"\"\"\n",
    "if not runs:\n",
    "    print(\"No runs found matching the criteria.\")\n",
    "else:\n",
    "    for run in runs:\n",
    "        print(run.outputs[\"model-Step 1: Classification\"])\n",
    "        print(run.outputs[\"model-Step 2: Summarization\"])\n",
    "\"\"\"\n",
    "DELETE_DATASET = True\n",
    "\n",
    "if DELETE_DATASET:\n",
    "  if client.has_dataset(dataset_name=dataset_name):\n",
    "      client.delete_dataset(dataset_name=dataset_name)\n",
    "      print(\"Deleted existing dataset\")\n",
    "  dataset = client.create_dataset(\n",
    "      dataset_name=dataset_name,\n",
    "      description=\"Default Dataset for Langsmith Development runs\",\n",
    "      inputs_schema={\n",
    "  \"type\": \"object\",\n",
    "  \"title\": \"dataset_input_schema\",\n",
    "  \"required\": [\n",
    "    \"step_1_classification\"\n",
    "  ],\n",
    "  \"properties\": {\n",
    "    \"step_1_classification\": {\n",
    "      \"type\": \"object\"\n",
    "    }\n",
    "  }\n",
    "}\n",
    "      ,\n",
    "      outputs_schema={\n",
    "  \"type\": \"object\",\n",
    "  \"title\": \"dataset_output_schema\",\n",
    "  \"required\": [\n",
    "    \"step_2_classification_summary\"\n",
    "  ],\n",
    "  \"properties\": {\n",
    "    \"step_2_classification_summary\": {\n",
    "      \"type\": \"string\"\n",
    "    }\n",
    "  }\n",
    "})\n",
    "\n",
    "else:\n",
    "  dataset=client.read_dataset(dataset_name=dataset_name)\n",
    "\n",
    "\n",
    "\n",
    "#output = json.loads(output) if isinstance(output, str) else output\n",
    "#print(run.id)\n",
    "\n",
    "#dataset = client.create_dataset(dataset_name, description=\"An example dataset\")\n",
    "for run in runs:\n",
    "  input= run.outputs[\"model-Step 1: Classification\"]\n",
    "  output=run.outputs[\"model-Step 2: Summarization\"]\n",
    "\n",
    "  input = json.loads(input) if isinstance(input, str) else input\n",
    "  client.create_example(\n",
    "      inputs={\"step_1_classification\": input},\n",
    "      outputs={\"step_2_classification_summary\": output},\n",
    "      metadata={\"user_id\": run.tags[1]},\n",
    "      created_at=run.end_time,\n",
    "      dataset_id=dataset.id,\n",
    "      split=\"dev\",\n",
    "      example_id=run.id,\n",
    "      source_run_id=run.id,\n",
    "      \n",
    "  )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20293681",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Client' object has no attribute 'get_dataset'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m client \u001b[38;5;241m=\u001b[39m Client()\n\u001b[1;32m      2\u001b[0m dataset_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf9ce2b77-2f54-4f3e-bc20-ad46d34ef303\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Replace with your actual dataset ID\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_dataset\u001b[49m(dataset_id)\n\u001b[1;32m      4\u001b[0m share_link \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mshare_link\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(share_link)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Client' object has no attribute 'get_dataset'"
     ]
    }
   ],
   "source": [
    "\n",
    "client = Client()\n",
    "dataset_id = \"f9ce2b77-2f54-4f3e-bc20-ad46d34ef303\"  # Replace with your actual dataset ID\n",
    "dataset = client.get_dataset(dataset_id)\n",
    "share_link = dataset.share_link\n",
    "print(share_link)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
